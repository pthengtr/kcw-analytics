{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-KiiutlOQxQ",
        "outputId": "4da451fd-19e4-44c2-a141-b5cbfe3410f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kcw-analytics'...\n",
            "remote: Enumerating objects: 387, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 387 (delta 111), reused 57 (delta 28), pack-reused 222 (from 1)\u001b[K\n",
            "Receiving objects: 100% (387/387), 315.61 KiB | 6.86 MiB/s, done.\n",
            "Resolving deltas: 100% (243/243), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pthengtr/kcw-analytics.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEOJaagmft1t",
        "outputId": "7b21f7f4-6733-4cc2-f8f5-3700fe85debf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/pthengtr/kcw-analytics\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!cd /content/kcw-analytics && git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7RReW8HfyTE",
        "outputId": "018e7983-e236-4e03-9c4d-4da6251dc37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37nxLdo-f6ic",
        "outputId": "30208ad7-b10c-4554-bd9e-018506df8907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: raw_inventory_hq_2024.csv -> (4983, 8)\n",
            "Loaded: raw_syp_pidet_purchase_lines.csv -> (27233, 41)\n",
            "Loaded: raw_syp_pimas_purchase_bills.csv -> (2915, 49)\n",
            "Loaded: raw_syp_simas_sales_bills.csv -> (12299, 49)\n",
            "Loaded: raw_syp_sidet_sales_lines.csv -> (36360, 38)\n",
            "Loaded: raw_hq_icmas_products.csv -> (114903, 94)\n",
            "Loaded: raw_hq_pidet_purchase_lines.csv -> (153589, 41)\n",
            "Loaded: raw_hq_pimas_purchase_bills.csv -> (50176, 49)\n",
            "Loaded: raw_hq_sidet_sales_lines.csv -> (732969, 38)\n",
            "Loaded: raw_hq_pvmas_notes_vouchers.csv -> (13730, 32)\n",
            "Loaded: raw_hq_simas_sales_bills.csv -> (275965, 49)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "folder = \"/content/drive/Shareddrives/KCW-Data/kcw_analytics/01_raw\"\n",
        "\n",
        "data = {}\n",
        "\n",
        "for file in os.listdir(folder):\n",
        "    if file.endswith(\".csv\"):\n",
        "        path = os.path.join(folder, file)\n",
        "        data[file] = pd.read_csv(\n",
        "            path,\n",
        "            dtype={\n",
        "              \"BCODE\": \"string\",\n",
        "              \"ITEMNO\": \"string\",\n",
        "              \"BILLNO\": \"string\",\n",
        "            },\n",
        "            encoding=\"utf-8-sig\",\n",
        "            low_memory=False   # stops chunk guessing\n",
        "        )\n",
        "        print(f\"Loaded: {file} -> {data[file].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def build_bill_summary_by_taxic(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    billno_col: str = \"BILLNO\",\n",
        "    billdate_col: str = \"BILLDATE\",\n",
        "    detail_col: str = \"DETAIL\",\n",
        "    amount_col: str = \"AMOUNT\",\n",
        "    taxic_col: str = \"TAXIC\",\n",
        "    tax_rate: float = 0.07,\n",
        "    tax_id_value: str = \"0000000000000\",\n",
        "    taxic_yes: str = \"Y\",\n",
        "):\n",
        "    \"\"\"\n",
        "    VAT logic:\n",
        "      TAXIC == Y : AMOUNT includes VAT\n",
        "      TAXIC == N : AMOUNT excludes VAT\n",
        "    \"\"\"\n",
        "\n",
        "    out = df.copy()\n",
        "    out[billno_col] = out[billno_col].astype(\"string\")\n",
        "    out[amount_col] = pd.to_numeric(out[amount_col], errors=\"coerce\").fillna(0)\n",
        "\n",
        "    # normalize TAXIC\n",
        "    if taxic_col not in out.columns:\n",
        "        out[taxic_col] = \"\"\n",
        "\n",
        "    out[taxic_col] = out[taxic_col].astype(\"string\").str.strip().str.upper()\n",
        "\n",
        "    # ===== pick DETAIL from highest AMOUNT row =====\n",
        "    idx_max_amt = out.groupby(billno_col)[amount_col].idxmax()\n",
        "    detail_pick = (\n",
        "        out.loc[idx_max_amt, [billno_col, detail_col]]\n",
        "        .set_index(billno_col)[detail_col]\n",
        "    )\n",
        "\n",
        "    # ===== group totals =====\n",
        "    totals = (\n",
        "        out.groupby(billno_col, as_index=False)\n",
        "        .agg(\n",
        "            TOTAL_AMOUNT=(amount_col, \"sum\"),\n",
        "            BILLDATE=(billdate_col, \"first\"),\n",
        "            TAXIC=(taxic_col, \"first\"),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    totals[detail_col] = totals[billno_col].map(detail_pick)\n",
        "\n",
        "    # ===== VAT calculation based on TAXIC =====\n",
        "    divisor = 1 + tax_rate\n",
        "    is_vat_inclusive = totals[\"TAXIC\"].eq(taxic_yes)\n",
        "\n",
        "    totals[\"BEFORE_VAT\"] = np.where(\n",
        "        is_vat_inclusive,\n",
        "        (totals[\"TOTAL_AMOUNT\"] / divisor).round(2),   # inclusive case\n",
        "        totals[\"TOTAL_AMOUNT\"].round(2)               # exclusive case\n",
        "    )\n",
        "\n",
        "    totals[\"VAT_AMOUNT\"] = np.where(\n",
        "        is_vat_inclusive,\n",
        "        (totals[\"TOTAL_AMOUNT\"] - totals[\"BEFORE_VAT\"]).round(2),\n",
        "        (totals[\"TOTAL_AMOUNT\"] * tax_rate).round(2)\n",
        "    )\n",
        "\n",
        "    # optional: total including VAT (very useful downstream)\n",
        "    totals[\"TOTAL_INCL_VAT\"] = (totals[\"BEFORE_VAT\"] + totals[\"VAT_AMOUNT\"]).round(2)\n",
        "\n",
        "    # TAX ID\n",
        "    totals[\"TAX_ID\"] = str(tax_id_value).zfill(13)[:13]\n",
        "\n",
        "    # SEQ\n",
        "    totals = totals.sort_values(billno_col).reset_index(drop=True)\n",
        "    totals[\"SEQ\"] = np.arange(1, len(totals) + 1)\n",
        "\n",
        "    return totals\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def map_simas_bill_fields(\n",
        "    df: pd.DataFrame,\n",
        "    df_simas: pd.DataFrame,\n",
        "    *,\n",
        "    billno_col: str = \"BILLNO\",\n",
        "    fields: tuple = (\"DEDUCT\", \"TAX\", \"AFTERTAX\"),\n",
        "    copy: bool = True,\n",
        "    verbose: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Join DEDUCT, TAX, AFTERTAX from df_simas into df using BILLNO.\n",
        "    \"\"\"\n",
        "\n",
        "    if billno_col not in df.columns:\n",
        "        raise ValueError(f\"{billno_col} not found in df\")\n",
        "\n",
        "    if billno_col not in df_simas.columns:\n",
        "        raise ValueError(f\"{billno_col} not found in df_simas\")\n",
        "\n",
        "    # --- normalize join keys (VERY important for legacy POS)\n",
        "    left = df.copy()\n",
        "    right = df_simas.copy()\n",
        "\n",
        "    left[\"_JOIN_KEY\"] = left[billno_col].astype(\"string\").str.strip().str.upper()\n",
        "    right[\"_JOIN_KEY\"] = right[billno_col].astype(\"string\").str.strip().str.upper()\n",
        "\n",
        "    # --- build lookup table (avoid duplicate explosion)\n",
        "    cols = [\"_JOIN_KEY\"] + [c for c in fields if c in right.columns]\n",
        "\n",
        "    lookup = (\n",
        "        right[cols]\n",
        "        .drop_duplicates(subset=[\"_JOIN_KEY\"], keep=\"first\")\n",
        "    )\n",
        "\n",
        "    # --- merge\n",
        "    result = left.merge(\n",
        "        lookup,\n",
        "        on=\"_JOIN_KEY\",\n",
        "        how=\"left\"\n",
        "    ).drop(columns=[\"_JOIN_KEY\"])\n",
        "\n",
        "    if copy:\n",
        "        result = result.copy()\n",
        "\n",
        "    if verbose:\n",
        "        matched = result[fields[0]].notna().sum()\n",
        "        print(f\"[map_simas_bill_fields] matched rows: {matched:,}/{len(result):,}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def filter_year_month(df, year, month, date_col=\"BILLDATE\"):\n",
        "    return df[pd.to_datetime(df[date_col]).dt.to_period(\"M\") == f\"{year}-{month:02d}\"]"
      ],
      "metadata": {
        "id": "kezaYmx5EO44"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Config: doc type prefixes per source\n",
        "BILLTYPE_RULES = {\n",
        "    \"hq\": {\n",
        "        \"TD\":  (\"TD\",),\n",
        "        \"TAD\": (\"TAD\",),\n",
        "        \"TR\":  (\"TR\",),\n",
        "        \"CN\":  (\"CN\",),\n",
        "    },\n",
        "    \"syp\": {\n",
        "        \"TD\":  (\"3TD\",),\n",
        "        \"TAD\": (\"3TAD\",),\n",
        "        \"TR\":  (\"3TR\",),\n",
        "        \"CN\":  (\"3CN\",),\n",
        "    },\n",
        "}\n",
        "\n",
        "def build_monthly_doc_summaries(\n",
        "    df_sidet: pd.DataFrame,\n",
        "    df_simas: pd.DataFrame,\n",
        "    *,\n",
        "    source: str,     # \"hq\" or \"syp\"\n",
        "    year: int,\n",
        "    month: int,\n",
        "    billno_col: str = \"BILLNO\",\n",
        "    date_col: str = \"BILLDATE\",\n",
        "    verbose: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Clean pipeline:\n",
        "      1) filter month\n",
        "      2) remove TF bills\n",
        "      3) split TD/TAD/TR/CN\n",
        "      4) build summary (TAXIC logic)\n",
        "      5) map SIMAS fields\n",
        "    \"\"\"\n",
        "\n",
        "    # ---- 1) filter month\n",
        "    df_m = filter_year_month(df_sidet, year, month)\n",
        "\n",
        "    # normalize billno once\n",
        "    s = df_m[billno_col].astype(\"string\").str.strip().str.upper()\n",
        "\n",
        "    # ---- 2) remove TF bills\n",
        "    df_m = df_m.loc[~s.str.startswith(\"TF\", na=False)].copy()\n",
        "    s = df_m[billno_col].astype(\"string\").str.strip().str.upper()\n",
        "\n",
        "    # ---- 3) prefix rules (simple, no config dict needed)\n",
        "    if source == \"hq\":\n",
        "        rules = {\n",
        "            \"TD\":  (\"TD\",),\n",
        "            \"TAD\": (\"TAD\",),\n",
        "            \"TR\":  (\"TR\",),\n",
        "            \"CN\":  (\"CN\",),\n",
        "        }\n",
        "    else:  # syp\n",
        "        rules = {\n",
        "            \"TD\":  (\"3TD\",),\n",
        "            \"TAD\": (\"3TAD\",),\n",
        "            \"TR\":  (\"3TR\",),\n",
        "            \"CN\":  (\"3CN\",),\n",
        "        }\n",
        "\n",
        "    out = {}\n",
        "\n",
        "    for doc_type, prefixes in rules.items():\n",
        "\n",
        "        mask = s.str.startswith(prefixes, na=False)\n",
        "        df_type = df_m.loc[mask].copy()\n",
        "\n",
        "        if df_type.empty:\n",
        "            out[doc_type] = df_type\n",
        "            if verbose:\n",
        "                print(f\"[{source}] {doc_type}: 0 rows\")\n",
        "            continue\n",
        "\n",
        "        # ---- 4) build summary (VAT logic by TAXIC)\n",
        "        summ = build_bill_summary_by_taxic(\n",
        "            df_type,\n",
        "            billno_col=billno_col,\n",
        "            billdate_col=date_col,\n",
        "        )\n",
        "\n",
        "        # ---- 5) map SIMAS fields\n",
        "        summ = map_simas_bill_fields(\n",
        "            summ,\n",
        "            df_simas,\n",
        "            billno_col=billno_col,\n",
        "            fields=(\"DEDUCT\", \"TAX\", \"AFTERTAX\"),\n",
        "            verbose=verbose,\n",
        "        )\n",
        "\n",
        "        out[doc_type] = summ\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[{source}] {doc_type}: {len(df_type):,} rows -> {len(summ):,} bills\")\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "noJbNV1cOSiJ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hq_sidet = data[\"raw_hq_sidet_sales_lines.csv\"].copy()\n",
        "df_syp_sidet = data[\"raw_syp_sidet_sales_lines.csv\"].copy()\n",
        "\n",
        "df_hq_simas = data[\"raw_hq_simas_sales_bills.csv\"].copy()\n",
        "df_syp_simas = data[\"raw_syp_simas_sales_bills.csv\"].copy()"
      ],
      "metadata": {
        "id": "V7ICm13IEoBz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = pd.to_datetime(df_hq_sidet[\"BILLDATE\"], errors=\"coerce\")\n",
        "\n",
        "YEAR  = dt.dt.year.max()\n",
        "MONTH = dt[dt.dt.year == YEAR].dt.month.max()\n",
        "\n",
        "print(YEAR, MONTH)"
      ],
      "metadata": {
        "id": "ihHlHgrYFEJv",
        "outputId": "73811921-d62a-4451-8d67-e0773192fa99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hq_summaries = build_monthly_doc_summaries(\n",
        "    df_hq_sidet, df_hq_simas,\n",
        "    source=\"hq\", year=YEAR, month=MONTH\n",
        ")\n",
        "\n",
        "syp_summaries = build_monthly_doc_summaries(\n",
        "    df_syp_sidet, df_syp_simas,\n",
        "    source=\"syp\", year=YEAR, month=MONTH\n",
        ")\n",
        "\n",
        "# Access:\n",
        "df_hq_td_summary  = hq_summaries[\"TD\"]\n",
        "df_hq_tad_summary = hq_summaries[\"TAD\"]\n",
        "df_hq_tr_summary  = hq_summaries[\"TR\"]\n",
        "df_hq_cn_summary  = hq_summaries[\"CN\"]\n",
        "\n",
        "df_syp_td_summary  = syp_summaries[\"TD\"]\n",
        "df_syp_tad_summary = syp_summaries[\"TAD\"]\n",
        "df_syp_tr_summary  = syp_summaries[\"TR\"]\n",
        "df_syp_cn_summary  = syp_summaries[\"CN\"]"
      ],
      "metadata": {
        "id": "AfxQdPOIOzKW",
        "outputId": "9a6a37dd-8d58-4739-f8cb-5a3cb273f96e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[map_simas_bill_fields] matched rows: 4/141\n",
            "[hq] TD: 315 rows -> 141 bills\n",
            "[map_simas_bill_fields] matched rows: 0/539\n",
            "[hq] TAD: 593 rows -> 539 bills\n",
            "[map_simas_bill_fields] matched rows: 0/27\n",
            "[hq] TR: 64 rows -> 27 bills\n",
            "[map_simas_bill_fields] matched rows: 41/41\n",
            "[hq] CN: 44 rows -> 41 bills\n",
            "[syp] TD: 0 rows\n",
            "[syp] TAD: 0 rows\n",
            "[map_simas_bill_fields] matched rows: 0/9\n",
            "[syp] TR: 37 rows -> 9 bills\n",
            "[syp] CN: 0 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kcwdir = '/content/drive/Shareddrives/KCW-Data'"
      ],
      "metadata": {
        "id": "zxx8r9QDRmrp"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "out_dir = f\"{kcwdir}/kcw_analytics/04_outputs/VAT_Sales/{YEAR}_{MONTH}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "exports = [\n",
        "    (df_hq_td_summary,  \"TD\"),\n",
        "    (df_hq_tad_summary, \"TAD\"),\n",
        "    (df_hq_tr_summary,  \"TR\"),\n",
        "    (df_hq_cn_summary,  \"CN\"),\n",
        "    (df_syp_td_summary,  \"3TD\"),\n",
        "    (df_syp_tad_summary, \"3TAD\"),\n",
        "    (df_syp_tr_summary,  \"3TR\"),\n",
        "    (df_syp_cn_summary,  \"3CN\"),\n",
        "]\n",
        "\n",
        "for df, name in exports:\n",
        "    path = f\"{out_dir}/{name}.csv\"\n",
        "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"Saved -> {path}\")"
      ],
      "metadata": {
        "id": "k5ROcdP7Kyad",
        "outputId": "45e7cb8a-2442-45b1-96dc-56002e598b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/Shareddrives/KCW-Data/kcw_analytics/04_outputs/VAT_Sales/2026_2/TD.csv\n",
            "Saved -> /content/drive/Shareddrives/KCW-Data/kcw_analytics/04_outputs/VAT_Sales/2026_2/TAD.csv\n",
            "Saved -> /content/drive/Shareddrives/KCW-Data/kcw_analytics/04_outputs/VAT_Sales/2026_2/TR.csv\n",
            "Saved -> /content/drive/Shareddrives/KCW-Data/kcw_analytics/04_outputs/VAT_Sales/2026_2/CN.csv\n",
            "Saved -> /content/drive/Shareddrives/KCW-Data/kcw_analytics/04_outputs/VAT_Sales/2026_2/3TD.csv\n",
            "Saved -> /content/drive/Shareddrives/KCW-Data/kcw_analytics/04_outputs/VAT_Sales/2026_2/3TAD.csv\n",
            "Saved -> /content/drive/Shareddrives/KCW-Data/kcw_analytics/04_outputs/VAT_Sales/2026_2/3TR.csv\n",
            "Saved -> /content/drive/Shareddrives/KCW-Data/kcw_analytics/04_outputs/VAT_Sales/2026_2/3CN.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GM_aZF3LSvfV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}