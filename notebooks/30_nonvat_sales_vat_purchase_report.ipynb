{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ1RsCwb9XjI",
        "outputId": "7f197802-0194-4c31-e72f-21f1afeaee92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'kcw-analytics' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pthengtr/kcw-analytics.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/kcw-analytics && git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV6e6jMp6p21",
        "outputId": "198107ed-90f2-4b19-ad4b-34283b729167"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/pthengtr/kcw-analytics\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2Cf0hDr6qKx",
        "outputId": "f3cd9e29-bf59-4d53-92b4-808d093bd20c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "folder = \"/content/drive/MyDrive/kcw_analytics/01_raw\"\n",
        "\n",
        "data = {}\n",
        "\n",
        "for file in os.listdir(folder):\n",
        "    if file.endswith(\".csv\"):\n",
        "        path = os.path.join(folder, file)\n",
        "        data[file] = pd.read_csv(\n",
        "            path,\n",
        "            dtype={\n",
        "              \"BCODE\": \"string\",\n",
        "              \"ITEMNO\": \"string\",\n",
        "              \"BILLNO\": \"string\",\n",
        "            },\n",
        "            encoding=\"utf-8-sig\",\n",
        "            low_memory=False   # stops chunk guessing\n",
        "        )\n",
        "        print(f\"Loaded: {file} -> {data[file].shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr-erE7EbNqj",
        "outputId": "2beca3c3-2c44-49ff-a597-015e8d2665b8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: raw_inventory_hq_2024.csv -> (4983, 8)\n",
            "Loaded: raw_hq_pimas_purchase_bills.csv -> (83130, 49)\n",
            "Loaded: raw_hq_sidet_sales_lines.csv -> (1194399, 38)\n",
            "Loaded: raw_hq_simas_sales_bills.csv -> (484283, 49)\n",
            "Loaded: raw_hq_pidet_purchase_lines.csv -> (247915, 41)\n",
            "Loaded: raw_syp_pimas_purchase_bills.csv -> (2829, 49)\n",
            "Loaded: raw_syp_simas_sales_bills.csv -> (11348, 49)\n",
            "Loaded: raw_syp_pidet_purchase_lines.csv -> (26431, 41)\n",
            "Loaded: raw_syp_sidet_sales_lines.csv -> (33314, 38)\n",
            "Loaded: raw_hq_icmas_products.csv -> (114825, 94)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import importlib\n",
        "\n",
        "# ensure repo is on path\n",
        "repo_path = \"/content/kcw-analytics\"\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)\n",
        "\n",
        "# import the module (NOT individual functions)\n",
        "import src.kcw.utils as utils\n",
        "\n",
        "# reload to pick up latest .py changes\n",
        "importlib.reload(utils)\n",
        "\n",
        "get_nonvat_sales_lines_last_purchase_vat = utils.get_nonvat_sales_lines_last_purchase_vat\n",
        "audit_bcode_nonvat_sales_last_purchase_vat = utils.audit_bcode_nonvat_sales_last_purchase_vat"
      ],
      "metadata": {
        "id": "SaFjpYIqKuzO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_year_month(df, year, month, date_col=\"BILLDATE\"):\n",
        "    return df[pd.to_datetime(df[date_col]).dt.to_period(\"M\") == f\"{year}-{month:02d}\"]"
      ],
      "metadata": {
        "id": "g77u44xwLJsk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def enrich_sales_with_newbillno_only(\n",
        "    sales_lines: pd.DataFrame,\n",
        "    *,\n",
        "    source: str,  # \"hq\" or \"syp\"\n",
        "    bcode_col: str = \"BCODE\",\n",
        "    date_col: str = \"BILLDATE\",\n",
        "    billno_col: str = \"BILLNO\",\n",
        "    output_cols: tuple = (\n",
        "        \"BCODE\", \"BILLDATE\", \"BILLNO\", \"DETAIL\", \"QTY\", \"MTP\", \"UI\", \"PRICE\", \"AMOUNT\",\n",
        "        \"ACCT_NO\", \"CANCELED\", \"ISVAT\"\n",
        "    ),\n",
        "    chunk_size: int = 20,  # keep same behavior as your current code\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds NEW_BILLNO without calculating any cost.\n",
        "\n",
        "    NEW_BILLNO:\n",
        "      - HQ  -> RV[BDyy][mm]-[seq]\n",
        "      - SYP -> 3RV[BDyy][mm]-[seq]\n",
        "      - seq resets per month\n",
        "      - within month: increments per DATE and per each additional chunk_size lines per DATE\n",
        "    \"\"\"\n",
        "    source = source.lower().strip()\n",
        "    if source not in (\"hq\", \"syp\"):\n",
        "        raise ValueError(\"source must be 'hq' or 'syp'\")\n",
        "    bill_prefix = \"TAR\" if source == \"hq\" else \"3TAR\"\n",
        "\n",
        "    def _clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        out = df.copy()\n",
        "        out.columns = out.columns.astype(str).str.replace(\"\\ufeff\", \"\", regex=False).str.strip()\n",
        "        return out\n",
        "\n",
        "    def _clean_bcode(s: pd.Series) -> pd.Series:\n",
        "        return s.astype(str).str.strip()\n",
        "\n",
        "    sales = _clean_cols(sales_lines).copy()\n",
        "\n",
        "    # validate required\n",
        "    for col in [bcode_col, date_col]:\n",
        "        if col not in sales.columns:\n",
        "            raise KeyError(f\"sales_lines missing required column: {col}\")\n",
        "\n",
        "    sales[bcode_col] = _clean_bcode(sales[bcode_col])\n",
        "    sales[date_col] = pd.to_datetime(sales[date_col], errors=\"coerce\")\n",
        "\n",
        "    sales = sales.dropna(subset=[bcode_col, date_col]).copy()\n",
        "    sales = sales[sales[bcode_col] != \"\"].copy()\n",
        "\n",
        "    # ---- NEW_BILLNO logic (same pattern as your original)\n",
        "    sales[\"__DATEKEY__\"] = sales[date_col].dt.normalize()\n",
        "    sales[\"__MONTHKEY__\"] = sales[\"__DATEKEY__\"].dt.to_period(\"M\")\n",
        "\n",
        "    sales = sales.sort_values([\"__DATEKEY__\", bcode_col], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    day_chunk = sales.groupby(\"__DATEKEY__\", sort=False).cumcount() // int(chunk_size)\n",
        "\n",
        "    day_tbl = (\n",
        "        pd.DataFrame({\n",
        "            \"__MONTHKEY__\": sales[\"__MONTHKEY__\"],\n",
        "            \"__DATEKEY__\": sales[\"__DATEKEY__\"],\n",
        "            \"day_chunk\": day_chunk\n",
        "        })\n",
        "        .groupby([\"__MONTHKEY__\", \"__DATEKEY__\"], sort=False)[\"day_chunk\"]\n",
        "        .max()\n",
        "        .rename(\"MAX_CHUNK\")\n",
        "        .reset_index()\n",
        "        .sort_values([\"__MONTHKEY__\", \"__DATEKEY__\"], kind=\"mergesort\")\n",
        "    )\n",
        "\n",
        "    day_tbl[\"DAY_START_SEQ0\"] = (\n",
        "        day_tbl.groupby(\"__MONTHKEY__\")[\"MAX_CHUNK\"]\n",
        "        .transform(lambda x: (x + 1).cumsum() - (x + 1))\n",
        "    )\n",
        "\n",
        "    start_map = day_tbl.set_index([\"__MONTHKEY__\", \"__DATEKEY__\"])[\"DAY_START_SEQ0\"]\n",
        "    sales[\"__DAY_START_SEQ0__\"] = start_map.loc[\n",
        "        list(zip(sales[\"__MONTHKEY__\"], sales[\"__DATEKEY__\"]))\n",
        "    ].to_numpy()\n",
        "\n",
        "    seq = (sales[\"__DAY_START_SEQ0__\"] + day_chunk + 1).astype(int)\n",
        "\n",
        "    bd_yy = ((sales[\"__DATEKEY__\"].dt.year + 543) % 100).astype(int)\n",
        "    mm = sales[\"__DATEKEY__\"].dt.month.astype(int)\n",
        "\n",
        "    sales[\"NEW_BILLNO\"] = (\n",
        "        bill_prefix\n",
        "        + bd_yy.map(lambda x: f\"{x:02d}\")\n",
        "        + mm.map(lambda x: f\"{x:02d}\")\n",
        "        + \"-\"\n",
        "        + seq.map(lambda x: f\"{x:03d}\")\n",
        "    )\n",
        "\n",
        "    sales.drop(columns=[\"__DATEKEY__\", \"__MONTHKEY__\", \"__DAY_START_SEQ0__\"], inplace=True)\n",
        "\n",
        "    # ensure output cols exist\n",
        "    for col in output_cols:\n",
        "        if col not in sales.columns:\n",
        "            sales[col] = pd.NA\n",
        "\n",
        "    return sales[list(output_cols) + [\"NEW_BILLNO\"]].copy()\n"
      ],
      "metadata": {
        "id": "e8FlSfZ9NWdm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y install libpango-1.0-0 libpangoft2-1.0-0 libcairo2 libgdk-pixbuf2.0-0 libffi-dev shared-mime-info\n",
        "!pip -q install weasyprint"
      ],
      "metadata": {
        "id": "P15f75EsOFas",
        "outputId": "ce88f858-242a-47f3-b283-f35abd09cc0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libffi-dev is already the newest version (3.4.2-4).\n",
            "shared-mime-info is already the newest version (2.1-2).\n",
            "libgdk-pixbuf2.0-0 is already the newest version (2.40.2-2build4).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpangoft2-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from weasyprint import HTML\n",
        "\n",
        "COMPANY_INFO = {\n",
        "    \"hq\": {\n",
        "        \"name\": \"บริษัท เกียรติชัยอะไหล่ยนต์ 2007 จำกัด (สำนักงานใหญ่)\",\n",
        "        \"address\": \"ที่อยู่ 305 ม.1 ต.ชุมแสง อ.วังจันทร์ จ.ระยอง 21210\",\n",
        "        \"phone\": \"โทร. 038-666-078\",\n",
        "        \"tax\": \"เลขประจำตัวผู้เสียภาษี 0215560000262\"\n",
        "    },\n",
        "    \"syp\": {\n",
        "        \"name\": \"บริษัท เกียรติชัยอะไหล่ยนต์ 2007 จำกัด (สาขาสี่แยกพัฒนา)\",\n",
        "        \"address\": \"ที่อยู่ 16/2 ม.2 ต.ห้วยทับมอญ อ.เขาชะเมา จ.ระยอง 21110\",\n",
        "        \"phone\": \"โทร. 063-2655387, 038-015818\",\n",
        "        \"tax\": \"เลขประจำตัวผู้เสียภาษี 0215560000262 (สาขาที่ 00003)\"\n",
        "    }\n",
        "}\n",
        "\n",
        "TH_MONTHS_ABBR = [\n",
        "    \"ม.ค.\", \"ก.พ.\", \"มี.ค.\", \"เม.ย.\", \"พ.ค.\", \"มิ.ย.\",\n",
        "    \"ก.ค.\", \"ส.ค.\", \"ก.ย.\", \"ต.ค.\", \"พ.ย.\", \"ธ.ค.\"\n",
        "]\n",
        "\n",
        "def get_company_info(new_billno: str):\n",
        "    if str(new_billno).startswith(\"3\"):\n",
        "        return COMPANY_INFO[\"syp\"]\n",
        "    return COMPANY_INFO[\"hq\"]\n",
        "\n",
        "def thai_date(d) -> str:\n",
        "    dt = pd.to_datetime(d).to_pydatetime()\n",
        "    return f\"{dt.day} {TH_MONTHS_ABBR[dt.month - 1]} {dt.year + 543}\"\n",
        "\n",
        "def _money(x):\n",
        "    try:\n",
        "        return f\"{float(x):,.2f}\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def build_one_receipt_weasy_vat(\n",
        "    group_df: pd.DataFrame,\n",
        "    pdf_path: str,\n",
        "    *,\n",
        "    font_regular_path: str,   # e.g. \"/content/drive/MyDrive/kcw_analytics/00_fonts/THSarabunNew.ttf\"\n",
        "    font_bold_path: str,      # e.g. \"/content/drive/MyDrive/kcw_analytics/00_fonts/THSarabunNew-Bold.ttf\"\n",
        "    signature_img_path: str | None = None,\n",
        "):\n",
        "    df = group_df.copy()\n",
        "\n",
        "    new_billno = str(df[\"NEW_BILLNO\"].iloc[0])\n",
        "    billdate = thai_date(df[\"BILLDATE\"].iloc[0])\n",
        "    src_billno = str(df[\"BILLNO\"].iloc[0]) if \"BILLNO\" in df.columns else \"\"\n",
        "\n",
        "    branch_text = \"สำนักงานใหญ่\"\n",
        "    if new_billno.startswith(\"3\"):\n",
        "        branch_text = \"สี่แยกพัฒนา\"\n",
        "\n",
        "    info = get_company_info(new_billno)\n",
        "\n",
        "    # numeric safety\n",
        "    df[\"QTY\"] = pd.to_numeric(df.get(\"QTY\", 0), errors=\"coerce\").fillna(0)\n",
        "    df[\"MTP\"] = pd.to_numeric(df.get(\"MTP\", 1), errors=\"coerce\").fillna(1)\n",
        "    df[\"PRICE\"] = pd.to_numeric(df.get(\"PRICE\", 0), errors=\"coerce\").fillna(0)\n",
        "    df[\"AMOUNT\"] = pd.to_numeric(df.get(\"AMOUNT\", 0), errors=\"coerce\").fillna(0)\n",
        "\n",
        "    # per-line VAT split (AMOUNT is VAT-inclusive)\n",
        "    # VAT portion for inclusive amount at 7% = amount * 7/107\n",
        "    df[\"VAT_PORTION\"] = df[\"AMOUNT\"] * (7.0 / 107.0)\n",
        "    df[\"BASE_EXVAT\"] = df[\"AMOUNT\"] - df[\"VAT_PORTION\"]\n",
        "\n",
        "    total_amount = float(df[\"AMOUNT\"].sum())\n",
        "    total_vat = float(df[\"VAT_PORTION\"].sum())\n",
        "    total_base = float(df[\"BASE_EXVAT\"].sum())\n",
        "\n",
        "    # rows HTML\n",
        "    rows_html = []\n",
        "    for _, r in df.iterrows():\n",
        "        bcode = str(r.get(\"BCODE\", \"\"))\n",
        "        detail = str(r.get(\"DETAIL\", \"\"))\n",
        "        unit_price = _money(r.get(\"PRICE\", 0))  # PRICE as UNIT_PRICE\n",
        "        qty_val = r.get(\"QTY\", 0)\n",
        "        qty = _money(qty_val) if (qty_val % 1) else str(int(qty_val))\n",
        "        unit = str(r.get(\"UI\", \"\"))\n",
        "\n",
        "        amount_incl = _money(r.get(\"AMOUNT\", 0))\n",
        "        vat_part = _money(r.get(\"VAT_PORTION\", 0))\n",
        "\n",
        "        rows_html.append(f\"\"\"\n",
        "          <tr>\n",
        "            <td class=\"c\">{bcode}</td>\n",
        "            <td class=\"l\">{detail}</td>\n",
        "            <td class=\"r\">{unit_price}</td>\n",
        "            <td class=\"r\">{qty}</td>\n",
        "            <td class=\"c\">{unit}</td>\n",
        "            <td class=\"r\">{amount_incl}</td>\n",
        "            <td class=\"r\">{vat_part}</td>\n",
        "          </tr>\n",
        "        \"\"\")\n",
        "\n",
        "    html = f\"\"\"\n",
        "<!doctype html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\"/>\n",
        "  <style>\n",
        "    @page {{\n",
        "      size: A4;\n",
        "      margin: 18px 24px;\n",
        "    }}\n",
        "\n",
        "    @font-face {{\n",
        "      font-family: \"THSarabunNew\";\n",
        "      src: url(\"{font_regular_path}\");\n",
        "    }}\n",
        "    @font-face {{\n",
        "      font-family: \"THSarabunNew\";\n",
        "      src: url(\"{font_bold_path}\");\n",
        "      font-weight: bold;\n",
        "    }}\n",
        "\n",
        "    body {{\n",
        "      font-family: \"THSarabunNew\";\n",
        "      font-size: 12pt;\n",
        "      line-height: 1.35;\n",
        "    }}\n",
        "\n",
        "    .title {{\n",
        "      margin-bottom: 6px;\n",
        "      text-align:left;\n",
        "      font-weight:700;\n",
        "      font-size:20px;\n",
        "    }}\n",
        "\n",
        "    .right {{\n",
        "      text-align: right;\n",
        "    }}\n",
        "\n",
        "    .kv b {{\n",
        "      font-weight: bold;\n",
        "    }}\n",
        "\n",
        "    table {{\n",
        "      width: 100%;\n",
        "      border-collapse: collapse;\n",
        "      margin-top: 8px;\n",
        "    }}\n",
        "    th, td {{\n",
        "      border: 1px solid #000;\n",
        "      padding: 4px 6px;\n",
        "      vertical-align: top;\n",
        "    }}\n",
        "    th {{\n",
        "      font-weight: bold;\n",
        "      background: #f5f5f5;\n",
        "      text-align: center;\n",
        "    }}\n",
        "\n",
        "    .l {{ text-align: left; }}\n",
        "    .c {{ text-align: center; }}\n",
        "    .r {{ text-align: right; }}\n",
        "\n",
        "    .totals {{\n",
        "      margin-top: 10px;\n",
        "      width: 100%;\n",
        "    }}\n",
        "    .totals .row {{\n",
        "      display: flex;\n",
        "      justify-content: flex-end;\n",
        "      gap: 10px;\n",
        "    }}\n",
        "    .totals .label {{\n",
        "      min-width: 140px;\n",
        "      text-align: right;\n",
        "      font-weight: bold;\n",
        "    }}\n",
        "    .totals .val {{\n",
        "      min-width: 120px;\n",
        "      text-align: right;\n",
        "    }}\n",
        "\n",
        "    .sign-block {{\n",
        "      margin-top: 18px;\n",
        "      display: flex;\n",
        "      flex-direction: column;\n",
        "      align-items: flex-end;\n",
        "      gap: 12px;\n",
        "    }}\n",
        "    .sign-row {{\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      gap: 10px;\n",
        "    }}\n",
        "    .sign-label {{\n",
        "      width: 80px;\n",
        "      text-align: center;\n",
        "      font-weight: bold;\n",
        "    }}\n",
        "    .sign-box {{\n",
        "      width: 200px;\n",
        "      height: 60px;\n",
        "      border: 1px solid #000;\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      justify-content: center;\n",
        "    }}\n",
        "    .sig-img {{\n",
        "      max-width: 180px;\n",
        "      max-height: 50px;\n",
        "    }}\n",
        "\n",
        "    .note {{\n",
        "      margin-top: 10px;\n",
        "      text-align: right;\n",
        "    }}\n",
        "\n",
        "    .header-row{{\n",
        "        display:flex;\n",
        "        justify-content:space-between;   /* push apart */\n",
        "        align-items:flex-start;\n",
        "        width:100%;\n",
        "    }}\n",
        "\n",
        "    .company{{\n",
        "        text-align:left;\n",
        "        font-size:14px;\n",
        "        line-height:1.4;\n",
        "        grid-column:1;\n",
        "        grid-row:1; }}\n",
        "    .company-name{{ font-weight:700; font-size:16px; }}\n",
        "    .company-line{{ font-size:14px; line-height:1.35; }}\n",
        "    .company-line.tax{{ margin-top:6px; }}\n",
        "  </style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "  <div class=\"header-row\">\n",
        "\n",
        "    <div class=\"company\">\n",
        "      <div class=\"company-name\">{info['name']}</div>\n",
        "      <div class=\"company-line\">{info['address']}</div>\n",
        "      <div class=\"company-line\">{info['phone']}</div>\n",
        "      <div class=\"company-line tax\">{info['tax']}</div>\n",
        "    </div>\n",
        "\n",
        "    <div>\n",
        "      <div class=\"title\">\n",
        "        ใบเสร็จรับเงิน/ใบกำกับภาษีอย่างย่อ\n",
        "      </div>\n",
        "      <div class=\"right kv\">\n",
        "        <div><b>เลขที่:</b> {new_billno}</div>\n",
        "        <div><b>วันที่:</b> {billdate}</div>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "  </div>\n",
        "\n",
        "  <table>\n",
        "    <thead>\n",
        "      <tr>\n",
        "        <th style=\"width: 12%\">รหัสสินค้า</th>\n",
        "        <th style=\"width: 36%\">รายการ</th>\n",
        "        <th style=\"width: 10%\">ราคา/หน่วย</th>\n",
        "        <th style=\"width: 8%\">จำนวน</th>\n",
        "        <th style=\"width: 8%\">หน่วย</th>\n",
        "        <th style=\"width: 13%\">รวมยอดเงิน<br/>(รวม VAT)</th>\n",
        "        <th style=\"width: 13%\">VAT 7%<br/>(ส่วนในยอด)</th>\n",
        "      </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "      {''.join(rows_html)}\n",
        "    </tbody>\n",
        "  </table>\n",
        "\n",
        "  <div class=\"totals\">\n",
        "    <div class=\"row\"><div class=\"label\">ยอดก่อน VAT:</div><div class=\"val\">{_money(total_base)}</div></div>\n",
        "    <div class=\"row\"><div class=\"label\">VAT 7%:</div><div class=\"val\">{_money(total_vat)}</div></div>\n",
        "    <div class=\"row\"><div class=\"label\">รวมทั้งสิ้น (รวม VAT):</div><div class=\"val\">{_money(total_amount)}</div></div>\n",
        "  </div>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "    HTML(string=html, base_url=\"/\").write_pdf(pdf_path)\n",
        "\n",
        "\n",
        "def build_receipts_by_new_billno_weasy_vat(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: str,\n",
        "    *,\n",
        "    font_regular_path: str,\n",
        "    font_bold_path: str,\n",
        "    signature_img_path: str | None = None,\n",
        "):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    if \"NEW_BILLNO\" not in df.columns:\n",
        "        raise ValueError(\"df must contain NEW_BILLNO column\")\n",
        "\n",
        "    groups = list(df.groupby(\"NEW_BILLNO\", sort=True))\n",
        "    total = len(groups)\n",
        "\n",
        "    print(f\"Generating {total} receipts...\\n\")\n",
        "\n",
        "    for i, (new_billno, g) in enumerate(groups, start=1):\n",
        "\n",
        "        # ---- Progress Line ----\n",
        "        pct = (i / total) * 100\n",
        "        print(f\"\\rProgress: {i}/{total}  ({pct:6.2f}%)  -> {new_billno}\", end=\"\")\n",
        "\n",
        "        pdf_path = os.path.join(out_dir, f\"{new_billno}.pdf\")\n",
        "\n",
        "        build_one_receipt_weasy_vat(\n",
        "            g,\n",
        "            pdf_path,\n",
        "            font_regular_path=font_regular_path,\n",
        "            font_bold_path=font_bold_path,\n",
        "            signature_img_path=signature_img_path\n",
        "        )\n",
        "\n",
        "    print(\"\\nDone.\")\n",
        "    return out_dir\n",
        "\n"
      ],
      "metadata": {
        "id": "WZ_wtAPVNemd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YEAR = 2026\n",
        "MONTH = 1\n",
        "\n",
        "nonvat_sales_lines_last_purchase_vat_hq = get_nonvat_sales_lines_last_purchase_vat(\n",
        "    data, year=YEAR, source=\"hq\"\n",
        ")\n",
        "\n",
        "nonvat_sales_lines_last_purchase_vat_syp = get_nonvat_sales_lines_last_purchase_vat(\n",
        "    data, year=YEAR, source=\"syp\"\n",
        ")"
      ],
      "metadata": {
        "id": "XTDEHsTCNq4f"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonvat_sales_lines_last_purchase_vat_hq = filter_year_month(nonvat_sales_lines_last_purchase_vat_hq, YEAR, MONTH)\n",
        "nonvat_sales_lines_last_purchase_vat_syp = filter_year_month(nonvat_sales_lines_last_purchase_vat_syp, YEAR, MONTH)"
      ],
      "metadata": {
        "id": "4qhoPZMkSzdc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = nonvat_sales_lines_last_purchase_vat_hq[\"BILLNO\"].astype(\"string\").str.startswith((\"TF\", \"TFV\"), na=False)\n",
        "\n",
        "removed_tf = nonvat_sales_lines_last_purchase_vat_hq.loc[mask].copy()\n",
        "nonvat_sales_lines_last_purchase_vat_hq = nonvat_sales_lines_last_purchase_vat_hq.loc[~mask].copy()\n",
        "\n",
        "print(f\"Removed TF/TFV lines: {len(removed_tf)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTdKDWqo5nNI",
        "outputId": "94fe6213-0500-492a-d299-1165c7360162"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed TF/TFV lines: 1102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = nonvat_sales_lines_last_purchase_vat_syp[\"BILLNO\"].astype(\"string\").str.startswith((\"TF\", \"TFV\"), na=False)\n",
        "\n",
        "removed_tf = nonvat_sales_lines_last_purchase_vat_syp.loc[mask].copy()\n",
        "nonvat_sales_lines_last_purchase_vat_syp = nonvat_sales_lines_last_purchase_vat_syp.loc[~mask].copy()\n",
        "\n",
        "print(f\"Removed TF/TFV lines: {len(removed_tf)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFUh_47-5n3F",
        "outputId": "89744e7a-da54-4e34-d655-073723d05d28"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed TF/TFV lines: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def remove_negative_and_monthend_offset(\n",
        "    sales: pd.DataFrame,\n",
        "    *,\n",
        "    date_col: str = \"BILLDATE\",\n",
        "    amount_col: str = \"AMOUNT_NUM\",   # use AMOUNT_NUM if you have it, else \"AMOUNT\"\n",
        "    cutoff_day: int = 15,\n",
        "    group_cols: tuple[str, ...] = (), # <-- month only by default\n",
        "    tie_break_cols: tuple[str, ...] = (\"BILLNO\", \"BCODE\"),\n",
        "):\n",
        "    \"\"\"\n",
        "    1) neg_df: remove all rows where AMOUNT < 0\n",
        "    2) removed_final_df: for each (group, month), remove rows from month-end backwards (only day > cutoff_day),\n",
        "       until sum(negatives) + sum(removed_final) >= 0\n",
        "    Returns: kept_df, neg_df, removed_final_df\n",
        "    \"\"\"\n",
        "    df = sales.copy()\n",
        "\n",
        "    # Ensure datetime\n",
        "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
        "\n",
        "    amt = pd.to_numeric(df[amount_col], errors=\"coerce\")\n",
        "\n",
        "    # (1) negatives\n",
        "    neg_mask = amt < 0\n",
        "    neg_df = df.loc[neg_mask].copy()\n",
        "    base_df = df.loc[~neg_mask].copy()\n",
        "\n",
        "    # month bucket\n",
        "    neg_df[\"_MONTH\"] = neg_df[date_col].dt.to_period(\"M\").dt.to_timestamp()\n",
        "    base_df[\"_MONTH\"] = base_df[date_col].dt.to_period(\"M\").dt.to_timestamp()\n",
        "\n",
        "    keys = list(group_cols) + [\"_MONTH\"]\n",
        "\n",
        "    # total negative per month (and group if provided)\n",
        "    neg_sum = (\n",
        "        neg_df.groupby(keys, dropna=False)[amount_col]\n",
        "        .sum()\n",
        "        .rename(\"NEG_SUM\")\n",
        "        .reset_index()\n",
        "    )\n",
        "    neg_sum[\"NEED_POS\"] = (-neg_sum[\"NEG_SUM\"]).clip(lower=0)\n",
        "\n",
        "    # (2) candidates: only day > cutoff_day, only months that actually have negatives\n",
        "    cand = base_df.loc[base_df[date_col].dt.day > cutoff_day].copy()\n",
        "    cand = cand.merge(neg_sum[keys + [\"NEED_POS\"]], on=keys, how=\"inner\")\n",
        "\n",
        "    if cand.empty:\n",
        "        removed_final_df = base_df.iloc[0:0].copy()\n",
        "        kept_df = base_df.drop(columns=[\"_MONTH\"], errors=\"ignore\")\n",
        "        neg_df = neg_df.drop(columns=[\"_MONTH\"], errors=\"ignore\")\n",
        "        return kept_df, neg_df, removed_final_df\n",
        "\n",
        "    # sort month-end backwards\n",
        "    sort_cols = [date_col]\n",
        "    asc = [False]\n",
        "    for c in tie_break_cols:\n",
        "        if c in cand.columns:\n",
        "            sort_cols.append(c)\n",
        "            asc.append(False)\n",
        "\n",
        "    cand = cand.sort_values(keys + sort_cols, ascending=[True]*len(keys) + asc, kind=\"mergesort\")\n",
        "\n",
        "    # cumulative positive removed\n",
        "    cand[\"_CUM_POS\"] = cand.groupby(keys, dropna=False)[amount_col].cumsum()\n",
        "\n",
        "    # remove prefix until crossing NEED_POS\n",
        "    cand[\"_REMOVE\"] = cand[\"_CUM_POS\"] <= cand[\"NEED_POS\"]\n",
        "    cand[\"_CROSS\"] = cand[\"_CUM_POS\"] >= cand[\"NEED_POS\"]\n",
        "    first_cross_idx = (\n",
        "        cand[cand[\"_CROSS\"]]\n",
        "        .groupby(keys, dropna=False, sort=False)\n",
        "        .head(1)\n",
        "        .index\n",
        "    )\n",
        "    cand.loc[first_cross_idx, \"_REMOVE\"] = True\n",
        "\n",
        "    removed_final_df = cand.loc[cand[\"_REMOVE\"]].copy()\n",
        "\n",
        "    # kept = base minus removed_final\n",
        "    if \"ROW_ID\" in base_df.columns and \"ROW_ID\" in removed_final_df.columns:\n",
        "        removed_ids = set(removed_final_df[\"ROW_ID\"].tolist())\n",
        "        kept_df = base_df.loc[~base_df[\"ROW_ID\"].isin(removed_ids)].copy()\n",
        "    else:\n",
        "        kept_df = base_df.drop(index=removed_final_df.index, errors=\"ignore\").copy()\n",
        "\n",
        "    # cleanup helper cols\n",
        "    for d in (kept_df, neg_df, removed_final_df):\n",
        "        d.drop(columns=[\"_MONTH\"], errors=\"ignore\", inplace=True)\n",
        "    removed_final_df.drop(columns=[\"NEED_POS\", \"_CUM_POS\", \"_REMOVE\", \"_CROSS\"], errors=\"ignore\", inplace=True)\n",
        "\n",
        "    return kept_df, neg_df, removed_final_df\n"
      ],
      "metadata": {
        "id": "p5HkhQ71ydjI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_hq_kept, out_hq_neg, out_hq_removed = remove_negative_and_monthend_offset(\n",
        "    nonvat_sales_lines_last_purchase_vat_hq,\n",
        "    date_col=\"BILLDATE\",\n",
        "    amount_col=\"AMOUNT\",   # recommended\n",
        "    cutoff_day=15,\n",
        "    group_cols=(),             # month only\n",
        ")\n",
        "\n",
        "print(\"HQ neg_df:\", len(out_hq_neg))\n",
        "print(\"HQ removed_final_df:\", len(out_hq_removed))\n",
        "print(\"HQ kept_df:\", len(out_hq_kept))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un5KeQ_-0LVh",
        "outputId": "1802290c-4855-4c5b-f7df-62a2b691c1aa"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HQ neg_df: 89\n",
            "HQ removed_final_df: 160\n",
            "HQ kept_df: 5355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_syp_kept, out_syp_neg, out_syp_removed = remove_negative_and_monthend_offset(\n",
        "    nonvat_sales_lines_last_purchase_vat_syp,\n",
        "    date_col=\"BILLDATE\",\n",
        "    amount_col=\"AMOUNT\",   # recommended\n",
        "    cutoff_day=15,\n",
        "    group_cols=(),             # month only\n",
        ")\n",
        "\n",
        "print(\"SYP neg_df:\", len(out_syp_neg))\n",
        "print(\"SYP removed_final_df:\", len(out_syp_removed))\n",
        "print(\"SYP kept_df:\", len(out_syp_kept))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "087C5jOr0tWv",
        "outputId": "3df6c0bb-7b0f-4a30-b836-8a11b04fdc97"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYP neg_df: 43\n",
            "SYP removed_final_df: 39\n",
            "SYP kept_df: 2196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) enrich bill numbers only\n",
        "out_hq_kept = enrich_sales_with_newbillno_only(\n",
        "    out_hq_kept,\n",
        "    source=\"hq\"\n",
        ")\n",
        "\n",
        "out_syp_kept = enrich_sales_with_newbillno_only(\n",
        "    out_syp_kept,\n",
        "    source=\"syp\"\n",
        ")"
      ],
      "metadata": {
        "id": "I0RDMaNnNkph"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "# WeasyPrint\n",
        "logging.getLogger(\"weasyprint\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"weasyprint.progress\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"weasyprint.CSS\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"weasyprint.HTML\").setLevel(logging.ERROR)\n",
        "\n",
        "# fontTools (the spam you're seeing)\n",
        "logging.getLogger(\"fontTools\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"fontTools.subset\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"fontTools.ttLib\").setLevel(logging.ERROR)\n",
        "\n",
        "# Optional: also silence warnings from fontTools tables\n",
        "logging.getLogger(\"fontTools.ttLib.tables\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "CcL2FrnMRPAY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = build_receipts_by_new_billno_weasy_vat(\n",
        "    out_hq_kept,\n",
        "    f\"/content/drive/MyDrive/kcw_analytics/04_outputs/TAR_{YEAR}_{MONTH}/PDF\",\n",
        "    font_regular_path=\"/content/drive/MyDrive/kcw_analytics/00_fonts/THSarabunNew/THSarabunNew.ttf\",\n",
        "    font_bold_path=\"/content/drive/MyDrive/kcw_analytics/00_fonts/THSarabunNew/THSarabunNew-Bold.ttf\",\n",
        "    signature_img_path=\"/content/drive/MyDrive/kcw_analytics/00_fonts/Signature.jpg\",\n",
        ")\n",
        "print(\"Saved to:\", out)"
      ],
      "metadata": {
        "id": "eYrzqxVvNwCQ",
        "outputId": "765ce331-3afe-4078-ee1a-9d1c19b9748f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 280 receipts...\n",
            "\n",
            "Progress: 280/280  (100.00%)  -> TAR6901-280\n",
            "Done.\n",
            "Saved to: /content/drive/MyDrive/kcw_analytics/04_outputs/TAR_2026_1/PDF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = build_receipts_by_new_billno_weasy_vat(\n",
        "    out_syp_kept,\n",
        "    f\"/content/drive/MyDrive/kcw_analytics/04_outputs/3TAR_{YEAR}_{MONTH}/PDF\",\n",
        "    font_regular_path=\"/content/drive/MyDrive/kcw_analytics/00_fonts/THSarabunNew/THSarabunNew.ttf\",\n",
        "    font_bold_path=\"/content/drive/MyDrive/kcw_analytics/00_fonts/THSarabunNew/THSarabunNew-Bold.ttf\",\n",
        "    signature_img_path=\"/content/drive/MyDrive/kcw_analytics/00_fonts/Signature.jpg\",\n",
        ")\n",
        "print(\"Saved to:\", out)"
      ],
      "metadata": {
        "id": "i8vADrgRP3R9",
        "outputId": "75520987-7eb0-4f9a-e551-1ba58d907b28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 125 receipts...\n",
            "\n",
            "Progress: 125/125  (100.00%)  -> 3TAR6901-125\n",
            "Done.\n",
            "Saved to: /content/drive/MyDrive/kcw_analytics/04_outputs/3TAR_2026_1/PDF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_dir_hq = f\"/content/drive/MyDrive/kcw_analytics/04_outputs/TAR_{YEAR}_{MONTH}/CSV\"\n",
        "\n",
        "os.makedirs(output_dir_hq, exist_ok=True)\n",
        "\n",
        "out_hq_kept.to_csv(f\"{output_dir_hq}/TAR_{YEAR}_{MONTH}_kept.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "out_hq_neg.to_csv(f\"{output_dir_hq}/TAR_{YEAR}_{MONTH}_neg.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "out_hq_removed.to_csv(f\"{output_dir_hq}/TAR_{YEAR}_{MONTH}_removed.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "output_dir_syp = f\"/content/drive/MyDrive/kcw_analytics/04_outputs/3TAR_{YEAR}_{MONTH}/CSV\"\n",
        "\n",
        "os.makedirs(output_dir_syp, exist_ok=True)\n",
        "\n",
        "out_syp_kept.to_csv(f\"{output_dir_syp}/3TAR_{YEAR}_{MONTH}_kept.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "out_syp_neg.to_csv(f\"{output_dir_syp}/3TAR_{YEAR}_{MONTH}_neg.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "out_syp_removed.to_csv(f\"{output_dir_syp}/3TAR_{YEAR}_{MONTH}_removed.csv\", index=False, encoding=\"utf-8-sig\")\n"
      ],
      "metadata": {
        "id": "UesYh2oqXIny"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}